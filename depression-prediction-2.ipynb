{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":84895,"databundleVersionId":10008389,"sourceType":"competition"},{"sourceId":9616093,"sourceType":"datasetVersion","datasetId":5868381}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Exploring Mental Health Data Competition\n\n## Goal \nTo use data from a mental health survey to explore factors that may cause individuals to experience depression.\n\n## Dataset Description\n\nThe dataset for this competition (both train and test) was generated from a deep learning model trained on the Depression Survey/Dataset for Analysis dataset. Feature distributions are close to, but not exactly the same, as the original. Feel free to use the original dataset as part of this competition, both to explore differences as well as to see whether incorporating the original in training improves model performance.\n\n### Notes:\n\nA number of data artifacts have been left in the synthetic dataset.\nThis is not a particularly difficult dataset to model. It may be interesting to focus on different ways to visualize the dataset.\nFiles\n\n* train.csv - the training dataset; class is the binary target (either e or p)\n* test.csv - the test dataset; your objective is to predict target class for each row\n* sample_submission.csv - a sample submission file in the correct format\n\n## Evaluation\n\nSubmissions are evaluated using **Accuracy Score**.","metadata":{}},{"cell_type":"markdown","source":"### **Contents:** \n 1. [Imports and data loading](#1)\n 2. [Exploratory Data Analysis](#2)\n 3. [Building a Machine Learning Model](#3)\n \n \n <a id=\"1\"></a>\n## 1. Imports and data loading","metadata":{}},{"cell_type":"code","source":"# Import packages for data manipulation\nimport pandas as pd\nimport numpy as np\nfrom scipy import stats\n\n# Import packages for data visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# This lets us see all of the columns, preventing Juptyer from redacting them.\npd.set_option(\"display.max_columns\", None)\n\n# Import packages for data modeling\nfrom sklearn.model_selection import GridSearchCV, train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay,classification_report\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\n\nfrom xgboost import XGBClassifier\n\n# Function that helps plot feature importance\nfrom xgboost import plot_importance\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2024-11-20T10:07:38.716570Z","iopub.execute_input":"2024-11-20T10:07:38.717056Z","iopub.status.idle":"2024-11-20T10:07:42.868794Z","shell.execute_reply.started":"2024-11-20T10:07:38.717010Z","shell.execute_reply":"2024-11-20T10:07:42.867322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load dataset into the training dataframe\ndf_train = pd.read_csv(\"/kaggle/input/playground-series-s4e11/train.csv\",  index_col='id')\ndf_train.head()","metadata":{"execution":{"iopub.status.busy":"2024-11-20T10:07:42.871050Z","iopub.execute_input":"2024-11-20T10:07:42.871711Z","iopub.status.idle":"2024-11-20T10:07:43.535166Z","shell.execute_reply.started":"2024-11-20T10:07:42.871657Z","shell.execute_reply":"2024-11-20T10:07:43.533992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load dataset into the test dataframe\ndf_test= pd.read_csv(\"/kaggle/input/playground-series-s4e11/test.csv\",  index_col='id')\ndf_test.head()","metadata":{"execution":{"iopub.status.busy":"2024-11-20T10:07:43.536522Z","iopub.execute_input":"2024-11-20T10:07:43.536960Z","iopub.status.idle":"2024-11-20T10:07:43.906473Z","shell.execute_reply.started":"2024-11-20T10:07:43.536920Z","shell.execute_reply":"2024-11-20T10:07:43.905270Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This dataset presents a typical scenario in machine learning where there are columns specific to sub-groups within the dataset. In this case, students and working professionals have some overlapping columns and others that are unique to each group. To tackle this effectively, there is a need to create 2 subgroups:\n* The column **Working Professional or Student** indicates the subgroup.\n\n<a id=\"2\"></a>\n## 2. Exploratory Data Analysis\n\n - Understand your variables\n - Clean your dataset (missing data, redundant data, outliers)\n\n### Gather basic information about the data","metadata":{}},{"cell_type":"code","source":"# Summary information\ndf_train.info()","metadata":{"execution":{"iopub.status.busy":"2024-11-20T10:07:43.908542Z","iopub.execute_input":"2024-11-20T10:07:43.909147Z","iopub.status.idle":"2024-11-20T10:07:44.001804Z","shell.execute_reply.started":"2024-11-20T10:07:43.909102Z","shell.execute_reply":"2024-11-20T10:07:44.000441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.describe()","metadata":{"execution":{"iopub.status.busy":"2024-11-20T10:07:44.003127Z","iopub.execute_input":"2024-11-20T10:07:44.003432Z","iopub.status.idle":"2024-11-20T10:07:44.111523Z","shell.execute_reply.started":"2024-11-20T10:07:44.003402Z","shell.execute_reply":"2024-11-20T10:07:44.110258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Check missing values","metadata":{}},{"cell_type":"code","source":"# Check for missing values\ndf_train.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2024-11-20T10:07:44.113030Z","iopub.execute_input":"2024-11-20T10:07:44.113509Z","iopub.status.idle":"2024-11-20T10:07:44.191362Z","shell.execute_reply.started":"2024-11-20T10:07:44.113455Z","shell.execute_reply":"2024-11-20T10:07:44.190027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Check duplicates","metadata":{}},{"cell_type":"code","source":"# Check for duplicates\ndf_train.duplicated().sum()","metadata":{"execution":{"iopub.status.busy":"2024-11-20T10:07:44.193209Z","iopub.execute_input":"2024-11-20T10:07:44.193690Z","iopub.status.idle":"2024-11-20T10:07:44.339664Z","shell.execute_reply.started":"2024-11-20T10:07:44.193623Z","shell.execute_reply":"2024-11-20T10:07:44.338074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Check outliers","metadata":{}},{"cell_type":"code","source":"# Create a boxplot to visualize distribution of `age` and detect any outliers\nplt.figure(figsize=(7,2))\nplt.title('Distribution of age', fontsize=10)\nsns.boxplot(x=df_train['Age'])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-11-20T10:07:44.341219Z","iopub.execute_input":"2024-11-20T10:07:44.341598Z","iopub.status.idle":"2024-11-20T10:07:44.576384Z","shell.execute_reply.started":"2024-11-20T10:07:44.341548Z","shell.execute_reply":"2024-11-20T10:07:44.574999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are no outliers in the \"age\" distribution.","metadata":{}},{"cell_type":"code","source":"# Determine the number of rows containing outliers\nQ1 = df_train[\"Age\"].quantile(0.25)\nQ3 = df_train[\"Age\"].quantile(0.75)\n\nage_iqr = Q3 - Q1\n\nage_upper_limit = Q3 + 1.5 * age_iqr\nage_lower_limit = Q1 - 1.5 * age_iqr\n\nage_outliers = df_train[(df_train[\"Age\"] > age_upper_limit) | (df_train[\"Age\"] < age_lower_limit)]\n\nprint(f\"Number of rows containing outliers: {age_outliers.shape[0]}\")","metadata":{"execution":{"iopub.status.busy":"2024-11-20T10:07:44.578110Z","iopub.execute_input":"2024-11-20T10:07:44.578515Z","iopub.status.idle":"2024-11-20T10:07:44.602284Z","shell.execute_reply.started":"2024-11-20T10:07:44.578476Z","shell.execute_reply":"2024-11-20T10:07:44.600451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now, we will examine variables and create plots to visualize relationships, especially between non-numerical variables in the data. This way we will have insights about their correlation with depression variable and we will choose wich variables to encode and wich one we should just drop.\n\n### Distribution of the depression by gender","metadata":{}},{"cell_type":"code","source":"# Create histogram to compare depression by gender or by student versus worker professional\nfig, ax = plt.subplots(1, 2, figsize = (10,4))\nsns.histplot(data=df_train, x=\"Gender\", hue=\"Depression\", multiple=\"dodge\",\n              shrink=.6, ax = ax[0])\nax[0].set_title(\"Distribution of depression by gender\", fontsize=10)\n\nsns.histplot(data=df_train, x=\"Working Professional or Student\", hue=\"Depression\", multiple=\"dodge\",\n              shrink=.6, ax = ax[1])\nax[1].set_title(\"Distribution of depression by Working Professional or Student\", fontsize=10)","metadata":{"execution":{"iopub.status.busy":"2024-11-20T10:07:44.606298Z","iopub.execute_input":"2024-11-20T10:07:44.607126Z","iopub.status.idle":"2024-11-20T10:07:45.608442Z","shell.execute_reply.started":"2024-11-20T10:07:44.607063Z","shell.execute_reply":"2024-11-20T10:07:45.606671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The histogram shows that there is no visible correlation between depression and the gender of the person. However, between the working categories of professionals or students there is a clear difference: only a small percentage of working professionals are experiencing depression while more than half students have depression. \n\n### Distribution of the depression by age","metadata":{}},{"cell_type":"code","source":"# Create histogram to compare depression by age\nplt.figure(figsize=(5,4))\nsns.histplot(data=df_train, x=\"Age\", hue=\"Depression\",\n             hue_order=[0, 1], shrink=.6, bins = 10)\nplt.title(\"Distribution of depression by Age\", fontsize=10);","metadata":{"execution":{"iopub.status.busy":"2024-11-20T10:07:45.610515Z","iopub.execute_input":"2024-11-20T10:07:45.611559Z","iopub.status.idle":"2024-11-20T10:07:46.117646Z","shell.execute_reply.started":"2024-11-20T10:07:45.611447Z","shell.execute_reply":"2024-11-20T10:07:46.116421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The graphic shows that the more young the person is the more likely it is that the person is suffering from depression.\n\n### Distribution of the depression by sleep duration","metadata":{}},{"cell_type":"code","source":"# Create histogram to compare depression by sleep duration\nplt.figure(figsize=(5,4))\nsleep_duration_4 = df_train[\"Sleep Duration\"].value_counts()[df_train[\"Sleep Duration\"].value_counts() > 1000].index\n\n# Step 2: Filter rows where 'Sleep Duration' is in the sleep_duration_4 list\ndf_sleep_duration = df_train[df_train[\"Sleep Duration\"].isin(sleep_duration_4)]\nsns.histplot(data=df_sleep_duration, x=\"Sleep Duration\", hue=\"Depression\",\n             hue_order=[0, 1], shrink=.6, bins = 4)\nplt.xticks(rotation = 90)\nplt.title(\"Distribution of depression by Sleep Duration\", fontsize=10);","metadata":{"execution":{"iopub.status.busy":"2024-11-20T10:07:46.119416Z","iopub.execute_input":"2024-11-20T10:07:46.119905Z","iopub.status.idle":"2024-11-20T10:07:46.697191Z","shell.execute_reply.started":"2024-11-20T10:07:46.119803Z","shell.execute_reply":"2024-11-20T10:07:46.696050Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The people sleeping less than 5 hours are more likely to have depression.\n\n#### Distribution of the depression by Dietary habits","metadata":{}},{"cell_type":"code","source":"# Create histogram to compare depression by Dietary Habits\nplt.figure(figsize=(5,4))\ndietary_habits_3 = df_train[\"Dietary Habits\"].value_counts()[df_train[\"Dietary Habits\"].value_counts() > 1000].index\n\n# Step 2: Filter rows where 'Dietary Habits' is in the dietary_habits_3 list\ndf_dietary_habits = df_train[df_train[\"Dietary Habits\"].isin(dietary_habits_3)]\nsns.histplot(data=df_dietary_habits, x=\"Dietary Habits\", hue=\"Depression\",\n             hue_order=[0, 1], shrink=.6, bins = 3)\nplt.xticks(rotation = 90)\nplt.title(\"Distribution of depression by Dietary Habits\", fontsize=10);","metadata":{"execution":{"iopub.status.busy":"2024-11-20T10:07:46.698501Z","iopub.execute_input":"2024-11-20T10:07:46.699713Z","iopub.status.idle":"2024-11-20T10:07:47.268392Z","shell.execute_reply.started":"2024-11-20T10:07:46.699671Z","shell.execute_reply":"2024-11-20T10:07:47.267228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Un unhealthy diet is more likely to lead a person to depression. \n\n### Distribution of the depression by Degree\n\nSplit the dataset into 2 groups: \n* Students \n* Professionals","metadata":{}},{"cell_type":"code","source":"students = df_train[df_train['Working Professional or Student'] == 'Student']\nprofessionals = df_train[df_train['Working Professional or Student'] == 'Working Professional']","metadata":{"execution":{"iopub.status.busy":"2024-11-20T10:07:47.269769Z","iopub.execute_input":"2024-11-20T10:07:47.270103Z","iopub.status.idle":"2024-11-20T10:07:47.326706Z","shell.execute_reply.started":"2024-11-20T10:07:47.270071Z","shell.execute_reply":"2024-11-20T10:07:47.325739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create histogram to compare depression by Degree\nplt.figure(figsize=(5,4))\ndegree_students = students[\"Degree\"].value_counts()[students[\"Degree\"].value_counts() > 1000].index\n\n# Step 2: Filter rows where 'Degree' is in the degree list\ndf_degree = students[students[\"Degree\"].isin(degree_students)]\nsns.histplot(data=df_degree, x=\"Degree\", hue=\"Depression\",\n             hue_order=[0, 1], shrink=.6, bins = 3)\nplt.xticks(rotation = 90)\nplt.title(\"Distribution of depression by Degree for students\", fontsize=10);","metadata":{"execution":{"iopub.status.busy":"2024-11-20T10:07:47.327943Z","iopub.execute_input":"2024-11-20T10:07:47.328285Z","iopub.status.idle":"2024-11-20T10:07:47.719405Z","shell.execute_reply.started":"2024-11-20T10:07:47.328250Z","shell.execute_reply":"2024-11-20T10:07:47.718243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create histogram to compare depression by Degree for professionals\nplt.figure(figsize=(5,4))\ndegree_professionals = professionals[\"Degree\"].value_counts()[professionals[\"Degree\"].value_counts() > 1000].index\n\n# Step 2: Filter rows where 'Degree' is in the degree list\ndf_degree = professionals[professionals[\"Degree\"].isin(degree_professionals)]\nsns.histplot(data=df_degree, x=\"Degree\", hue=\"Depression\",\n             hue_order=[0, 1], shrink=.6, bins = 3)\nplt.xticks(rotation = 90)\nplt.title(\"Distribution of depression by Degree for professionals\", fontsize=10);","metadata":{"execution":{"iopub.status.busy":"2024-11-20T10:07:47.721098Z","iopub.execute_input":"2024-11-20T10:07:47.721588Z","iopub.status.idle":"2024-11-20T10:07:48.561277Z","shell.execute_reply.started":"2024-11-20T10:07:47.721534Z","shell.execute_reply":"2024-11-20T10:07:48.559867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It looks like the most depressed people are the ones with the Class12 degree. Between the other cathegories, depressed people looks fairly distributed.\n\n#### Distribution of the depression by suicidal thoughts and family history of mental illness","metadata":{}},{"cell_type":"code","source":"# Create histogram to compare depression by suicidal thoughts and family history of mental illness\nfig, ax = plt.subplots(1, 2, figsize = (10,4))\nsns.histplot(data=df_train, x=\"Have you ever had suicidal thoughts ?\", hue=\"Depression\", multiple=\"dodge\",\n              shrink=.6, ax = ax[0])\nax[0].set_title(\"Distribution of depression by suicidal thoughts ? \", fontsize=10)\n\nsns.histplot(data=df_train, x=\"Family History of Mental Illness\", hue=\"Depression\", multiple=\"dodge\",\n              shrink=.6, ax = ax[1])\nax[1].set_title(\"Distribution of depression by Family History of Mental Illness\", fontsize=10)","metadata":{"execution":{"iopub.status.busy":"2024-11-20T10:07:48.563121Z","iopub.execute_input":"2024-11-20T10:07:48.563600Z","iopub.status.idle":"2024-11-20T10:07:49.463352Z","shell.execute_reply.started":"2024-11-20T10:07:48.563548Z","shell.execute_reply":"2024-11-20T10:07:49.462049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The Family History of Mental Illness doesn't look to have a strong correlation with depression value. However, the suicidal thoughts do have an obvious corelation. \n\n### The heatmap of correlation between the depression and other variables.\n\nCheck for strong correlations between variables in the dataset.","metadata":{}},{"cell_type":"code","source":"# Eliminate columns that contain non-numeric data.\ncorr_df = students.select_dtypes(include=['float64', 'int64'])\n\n# Plot a correlation heatmap\nplt.figure(figsize=(16, 9))\nsns.heatmap(corr_df.corr(), cmap='Blues', annot=True)\nplt.title(\"Correlation Heatmap for students\", fontsize=14)","metadata":{"execution":{"iopub.status.busy":"2024-11-20T10:07:49.465113Z","iopub.execute_input":"2024-11-20T10:07:49.465627Z","iopub.status.idle":"2024-11-20T10:07:50.168586Z","shell.execute_reply.started":"2024-11-20T10:07:49.465573Z","shell.execute_reply":"2024-11-20T10:07:50.167060Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Eliminate columns that contain non-numeric data.\ncorr_df = professionals.select_dtypes(include=['float64', 'int64'])\n\n# Plot a correlation heatmap\nplt.figure(figsize=(16, 9))\nsns.heatmap(corr_df.corr(), cmap='Blues', annot=True)\nplt.title(\"Correlation Heatmap for professionals\", fontsize=14)","metadata":{"execution":{"iopub.status.busy":"2024-11-20T10:07:50.170167Z","iopub.execute_input":"2024-11-20T10:07:50.170544Z","iopub.status.idle":"2024-11-20T10:07:50.880986Z","shell.execute_reply.started":"2024-11-20T10:07:50.170506Z","shell.execute_reply":"2024-11-20T10:07:50.879771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the correlation heatmap we can conclude that the variables: Academic Pressure, Work Pressure, CGPA, Work/Study hours, Financial Stress are positively correlated with the depression variable, while the likelihood of having a depression is negatively correlated with Study or Job Satisfaction and age. \n \n<a id=\"4\"></a> \n## 3. Data Preprocessing\n\nBased on the \"Working Professional or Student\" column we are creating two separate subsets:\n* Students specific columns: **Academic Pressure**, **CGPA**, **Study, Staisfaction**\n* Working Professionals specific columns: **Profession**, **Work Pressure**, **Job Satisfaction**","metadata":{}},{"cell_type":"code","source":"# Handle missing values for each subgroup\nstudent_features = ['Academic Pressure', 'Study Satisfaction']\nprofessional_features = ['Work Pressure', 'Job Satisfaction']","metadata":{"execution":{"iopub.status.busy":"2024-11-20T10:07:50.882459Z","iopub.execute_input":"2024-11-20T10:07:50.882940Z","iopub.status.idle":"2024-11-20T10:07:50.888837Z","shell.execute_reply.started":"2024-11-20T10:07:50.882873Z","shell.execute_reply":"2024-11-20T10:07:50.887458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"First, we will drop some columns that are irrelevant to our model training:\n* Name;\n* City;\n* Profession.","metadata":{}},{"cell_type":"code","source":"# Drop the columns: Name, City, CGPA, Degree, Profession\nstudents.drop([\"Name\", \"City\", \"Profession\", \"CGPA\",\n               \"Work Pressure\", \"Job Satisfaction\", \n               'Working Professional or Student'], axis = 1, inplace = True)\nprofessionals.drop([\"Name\", \"City\", \"Profession\", \n                    \"Academic Pressure\", \"Study Satisfaction\", \n                    \"CGPA\", 'Working Professional or Student'], axis = 1, inplace = True)\n\n# Same for test data\ndf_test.drop([\"Name\", \"City\", \"Profession\"], axis = 1, inplace = True)\n\nstudents_test = df_test[df_test['Working Professional or Student'] == 'Student']\nprofessionals_test = df_test[df_test['Working Professional or Student'] == 'Working Professional']\n\nstudents_test.drop([\"Work Pressure\", \"Job Satisfaction\", 'Working Professional or Student', \"CGPA\"], axis = 1, inplace = True)\nprofessionals_test.drop([\"Academic Pressure\", \"Study Satisfaction\", \"CGPA\", 'Working Professional or Student'], axis = 1, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2024-11-20T10:07:50.890716Z","iopub.execute_input":"2024-11-20T10:07:50.891235Z","iopub.status.idle":"2024-11-20T10:07:50.963331Z","shell.execute_reply.started":"2024-11-20T10:07:50.891179Z","shell.execute_reply":"2024-11-20T10:07:50.962003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### The prediction target.\n\nThe predicted variable is “Depression” and it is already a binary variable.\n\n### Handle Missing Values.\n\nColumns like \"Academic Pressure\" and \"CGPA\" have many missing values for non-students. Similarly, \"Work Pressure\" has missing values for non-professionals.\n","metadata":{}},{"cell_type":"code","source":"# Create pipelines for each group\nstudent_pipeline = Pipeline([\n    ('imputer', SimpleImputer(strategy='mean')),\n    ('scaler', StandardScaler())\n])\n\nprofessional_pipeline = Pipeline([\n    ('imputer', SimpleImputer(fill_value = 0)),\n    ('scaler', StandardScaler())\n])\n\n# Apply transformations\nstudents[student_features] = student_pipeline.fit_transform(students[student_features])\nprofessionals[professional_features] = professional_pipeline.fit_transform(professionals[professional_features])\n\n# Apply transformation for test data\nstudents_test[student_features] = student_pipeline.transform(students_test[student_features])\nprofessionals_test[professional_features] = professional_pipeline.transform(professionals_test[professional_features])","metadata":{"execution":{"iopub.status.busy":"2024-11-20T10:07:50.964958Z","iopub.execute_input":"2024-11-20T10:07:50.965440Z","iopub.status.idle":"2024-11-20T10:07:51.003267Z","shell.execute_reply.started":"2024-11-20T10:07:50.965376Z","shell.execute_reply":"2024-11-20T10:07:51.002115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fill missing values\nstudents['Academic Pressure'].fillna(students['Academic Pressure'].mean(), inplace=True)\nstudents['Study Satisfaction'].fillna(students['Study Satisfaction'].mean(), inplace=True)\n\nprofessionals['Work Pressure'].fillna(professionals['Work Pressure'].mean(), inplace=True)\nprofessionals['Job Satisfaction'].fillna(professionals['Job Satisfaction'].mean(), inplace=True)\n\n# Test data: Fill missing values\nstudents_test['Academic Pressure'].fillna(students_test['Academic Pressure'].mean(), inplace=True)\nstudents_test['Study Satisfaction'].fillna(students_test['Study Satisfaction'].mean(), inplace=True)\n\nprofessionals_test['Work Pressure'].fillna(professionals_test['Work Pressure'].mean(), inplace=True)\nprofessionals_test['Job Satisfaction'].fillna(professionals_test['Job Satisfaction'].mean(), inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-11-20T10:07:51.004799Z","iopub.execute_input":"2024-11-20T10:07:51.005161Z","iopub.status.idle":"2024-11-20T10:07:51.020336Z","shell.execute_reply.started":"2024-11-20T10:07:51.005128Z","shell.execute_reply":"2024-11-20T10:07:51.019026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fix for Work Pressure (irrelevant for students)\nprofessionals['Work Pressure'].fillna(0, inplace=True)\n\n# Fix for Job Satisfaction (irrelevant for students)\nprofessionals['Job Satisfaction'].fillna(0, inplace=True)\n\n# Fix for Dietary Habits (small number of missing values)\nmost_freq_diet_stud = students['Dietary Habits'].mode()[0]\nstudents['Dietary Habits'].fillna(most_freq_diet_stud, inplace=True)\nmost_freq_diet_prof = professionals['Dietary Habits'].mode()[0]\nprofessionals['Dietary Habits'].fillna(most_freq_diet_prof, inplace=True)\n\n# Fix for Financial Stress (small number of missing values)\nmedian_fin_stress_stud = students['Financial Stress'].median()\nstudents['Financial Stress'].fillna(median_fin_stress_stud, inplace=True)\nmedian_fin_stress_prof = professionals['Financial Stress'].median()\nprofessionals['Financial Stress'].fillna(median_fin_stress_prof, inplace=True)\n\n# Fix for Degree(small number of missing values)\nmost_freq_degree = df_train['Degree'].mode()[0]\nprofessionals[\"Degree\"].fillna(most_freq_degree, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-11-20T10:07:51.022191Z","iopub.execute_input":"2024-11-20T10:07:51.022565Z","iopub.status.idle":"2024-11-20T10:07:51.082367Z","shell.execute_reply.started":"2024-11-20T10:07:51.022530Z","shell.execute_reply":"2024-11-20T10:07:51.081079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(students.isna().sum())\nprint(professionals.isna().sum())","metadata":{"execution":{"iopub.status.busy":"2024-11-20T10:07:51.083958Z","iopub.execute_input":"2024-11-20T10:07:51.084337Z","iopub.status.idle":"2024-11-20T10:07:51.139732Z","shell.execute_reply.started":"2024-11-20T10:07:51.084301Z","shell.execute_reply":"2024-11-20T10:07:51.138271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Same for test data\nstudents_test.fillna(0, inplace=True)\nprofessionals_test.fillna(0, inplace=True)\n\n# Fix for Dietary Habits (small number of missing values)\nmost_freq_diet_stud_test = students_test['Dietary Habits'].mode()[0]\nstudents_test['Dietary Habits'].fillna(most_freq_diet_stud_test, inplace=True)\nmost_freq_diet_prof_test = professionals_test['Dietary Habits'].mode()[0]\nprofessionals_test['Dietary Habits'].fillna(most_freq_diet_prof_test, inplace=True)\n\n# Fix for Financial Stress (small number of missing values)\nmedian_fin_stress_stud_test = students_test['Financial Stress'].median()\nstudents_test['Financial Stress'].fillna(median_fin_stress_stud_test, inplace=True)\nmedian_fin_stress_prof_test = professionals_test['Financial Stress'].median()\nprofessionals_test['Financial Stress'].fillna(median_fin_stress_prof_test, inplace=True)\n\n# Fix for Degree(small number of missing values)\nmost_freq_degree_test= df_test['Degree'].mode()[0]\nprofessionals_test[\"Degree\"].fillna(most_freq_degree_test, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-11-20T10:07:51.141296Z","iopub.execute_input":"2024-11-20T10:07:51.141835Z","iopub.status.idle":"2024-11-20T10:07:51.222959Z","shell.execute_reply.started":"2024-11-20T10:07:51.141774Z","shell.execute_reply":"2024-11-20T10:07:51.221726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(students_test.isna().sum())\nprint(professionals_test.isna().sum())","metadata":{"execution":{"iopub.status.busy":"2024-11-20T10:07:51.224320Z","iopub.execute_input":"2024-11-20T10:07:51.224831Z","iopub.status.idle":"2024-11-20T10:07:51.265603Z","shell.execute_reply.started":"2024-11-20T10:07:51.224772Z","shell.execute_reply":"2024-11-20T10:07:51.264155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"###  Cleaning the variables for encoding.\n\nWe will use the following non-numerical variables that need to be encoded in order to be used in the model training:\n* Sleep Duration;\n* Dietary Habits.","metadata":{}},{"cell_type":"code","source":"less_than_5 = [\"Less than 5 hours\", \"3-4 hours\", \"4-5 hours\", \"2-3 hours\", \"1-6 hours\", \"No\", \"45\", \"3-6 hours\", \"1-3 hours\", \"than 5 hours\" ]\nhours_5_6 = [\"5-6 hours\", \"4-6 hours\" ]\nhours_6_7 = [\"6-7 hours\", \"6-8 hours\", \"moderate\"]\nhours_7_8 = [\"7-8 hours\"]\nmore_than_8 = [\"More than 8 hours\", \"9-11 hours\", \"10-11 hours\", \"8-9 hours\", \"49 hours\" ]\n\nall_my_lists = less_than_5 + hours_5_6 + hours_6_7 + hours_7_8 + more_than_8\n\nstudents.loc[students['Sleep Duration'].isin(less_than_5), 'Sleep Duration'] = 'Less than 5 hours'\nstudents.loc[students['Sleep Duration'].isin(hours_5_6), 'Sleep Duration'] = '5-6 hours'\nstudents.loc[students['Sleep Duration'].isin(hours_6_7), 'Sleep Duration'] = '6-7 hours'\nstudents.loc[students['Sleep Duration'].isin(more_than_8), 'Sleep Duration'] = 'More than 8 hours'\n\nprofessionals.loc[professionals['Sleep Duration'].isin(less_than_5), 'Sleep Duration'] = 'Less than 5 hours'\nprofessionals.loc[professionals['Sleep Duration'].isin(hours_5_6), 'Sleep Duration'] = '5-6 hours'\nprofessionals.loc[professionals['Sleep Duration'].isin(hours_6_7), 'Sleep Duration'] = '6-7 hours'\nprofessionals.loc[professionals['Sleep Duration'].isin(more_than_8), 'Sleep Duration'] = 'More than 8 hours'\n\n# Fill the rest with most frequent values\nstudents.loc[~students['Sleep Duration'].isin(all_my_lists), 'Sleep Duration'] = students['Sleep Duration'].mode()[0]\nprofessionals.loc[~professionals['Sleep Duration'].isin(all_my_lists), 'Sleep Duration'] = professionals['Sleep Duration'].mode()[0]","metadata":{"execution":{"iopub.status.busy":"2024-11-20T10:07:51.271493Z","iopub.execute_input":"2024-11-20T10:07:51.272864Z","iopub.status.idle":"2024-11-20T10:07:51.343965Z","shell.execute_reply.started":"2024-11-20T10:07:51.272815Z","shell.execute_reply":"2024-11-20T10:07:51.342566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Same for test data\nstudents_test.loc[students_test['Sleep Duration'].isin(less_than_5), 'Sleep Duration'] = 'Less than 5 hours'\nstudents_test.loc[students_test['Sleep Duration'].isin(hours_5_6), 'Sleep Duration'] = '5-6 hours'\nstudents_test.loc[students_test['Sleep Duration'].isin(hours_6_7), 'Sleep Duration'] = '6-7 hours'\nstudents_test.loc[students_test['Sleep Duration'].isin(more_than_8), 'Sleep Duration'] = 'More than 8 hours'\n\nprofessionals_test.loc[professionals_test['Sleep Duration'].isin(less_than_5), 'Sleep Duration'] = 'Less than 5 hours'\nprofessionals_test.loc[professionals_test['Sleep Duration'].isin(hours_5_6), 'Sleep Duration'] = '5-6 hours'\nprofessionals_test.loc[professionals_test['Sleep Duration'].isin(hours_6_7), 'Sleep Duration'] = '6-7 hours'\nprofessionals_test.loc[professionals_test['Sleep Duration'].isin(more_than_8), 'Sleep Duration'] = 'More than 8 hours'\n\n# Fill the rest with most frequent values\nprofessionals_test.loc[~professionals_test['Sleep Duration'].isin(all_my_lists), 'Sleep Duration'] = professionals_test['Sleep Duration'].mode()[0]\nstudents_test.loc[~students_test['Sleep Duration'].isin(all_my_lists), 'Sleep Duration'] = students_test['Sleep Duration'].mode()[0]","metadata":{"execution":{"iopub.status.busy":"2024-11-20T10:07:51.345712Z","iopub.execute_input":"2024-11-20T10:07:51.346267Z","iopub.status.idle":"2024-11-20T10:07:51.400315Z","shell.execute_reply.started":"2024-11-20T10:07:51.346199Z","shell.execute_reply":"2024-11-20T10:07:51.398951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fill the rest with most frequent values\ndiet_list = [\"Moderate\", \"Healthy\", \"Unhealthy\"]\nstudents.loc[~students['Dietary Habits'].isin(diet_list), 'Dietary Habits'] = students['Dietary Habits'].mode()[0]\nprofessionals.loc[~professionals['Dietary Habits'].isin(diet_list), 'Dietary Habits'] = professionals['Dietary Habits'].mode()[0]\n\n# Same for test data\nstudents_test.loc[~students_test['Dietary Habits'].isin(diet_list), 'Dietary Habits'] = students_test['Dietary Habits'].mode()[0]\nprofessionals_test.loc[~professionals_test['Dietary Habits'].isin(diet_list), 'Dietary Habits'] = professionals_test['Dietary Habits'].mode()[0]","metadata":{"execution":{"iopub.status.busy":"2024-11-20T10:07:51.401782Z","iopub.execute_input":"2024-11-20T10:07:51.402165Z","iopub.status.idle":"2024-11-20T10:07:51.452657Z","shell.execute_reply.started":"2024-11-20T10:07:51.402118Z","shell.execute_reply":"2024-11-20T10:07:51.451428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Prepare the \"Degree\" most frequent values for students and for professionals.","metadata":{}},{"cell_type":"code","source":"# Fill the rest with more frequent values\nstudents.loc[~students['Degree'].isin(degree_students), 'Degree'] = \"Other\"\nprofessionals.loc[~professionals['Degree'].isin(degree_professionals), 'Degree'] = \"Other\"\n\n# Same for test data\\\ndegree_students_test = students_test[\"Degree\"].value_counts()[students_test[\"Degree\"].value_counts() > 1000].index\nstudents_test.loc[~students_test['Degree'].isin(degree_students_test), 'Degree'] = \"Other\"\n\ndegree_professionals_test = professionals_test[\"Degree\"].value_counts()[professionals_test[\"Degree\"].value_counts() > 1000].index\nprofessionals_test.loc[~professionals_test['Degree'].isin(degree_professionals_test), 'Degree'] = \"Other\"","metadata":{"execution":{"iopub.status.busy":"2024-11-20T10:07:51.453917Z","iopub.execute_input":"2024-11-20T10:07:51.454397Z","iopub.status.idle":"2024-11-20T10:07:51.498188Z","shell.execute_reply.started":"2024-11-20T10:07:51.454336Z","shell.execute_reply":"2024-11-20T10:07:51.496589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"4\"></a>\n## 4. Building a Machine Learning Model\n\n - Fit the model that predicts the outcome variable using two or more independent variables\n - Check model assumptions\n - Evaluate the model\n\n\n\n### Types of models most appropriate for this task.\nFor this project, I choose XGBoost models to predict depression. This model is effective in handling complex relationships and non-linear patterns.\n \n**XGBoost**:\n - XGBoost is known for its superior accuracy and speed, especially with large datasets.\n - It deals well with imbalanced data, which is common in turnover prediction (e.g., fewer employees leaving compared to staying).\n - XGBoost optimizes computation and performs well with missing data or noisy inputs.\n - It can be easily fine-tuned, which gives more flexibility in improving model performance.\n \n### Spliting the data","metadata":{}},{"cell_type":"code","source":"# Separate the dataset into labels (y) and features (X).\n# Define the X (predictor) variables X1 for students and X2 for professionals\nX1 = students.drop(\"Depression\",axis=1)\nX2 = professionals.drop(\"Depression\",axis=1)\n# Define the y (target) variable\ny1 = students[\"Depression\"]\ny2 = professionals[\"Depression\"]\n\n# Split the data into training set and testing set\nX1_train, X1_valid, y1_train, y1_valid = train_test_split(X1, y1, test_size=0.25, \n                                                    stratify=y1, random_state=24)\nX2_train, X2_valid, y2_train, y2_valid = train_test_split(X2, y2, test_size=0.25, \n                                                    stratify=y2, random_state=24)\n\nX1_test = students_test.copy()\nX2_test = professionals_test.copy()","metadata":{"execution":{"iopub.status.busy":"2024-11-20T10:07:51.499805Z","iopub.execute_input":"2024-11-20T10:07:51.500296Z","iopub.status.idle":"2024-11-20T10:07:51.630332Z","shell.execute_reply.started":"2024-11-20T10:07:51.500245Z","shell.execute_reply":"2024-11-20T10:07:51.629088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" ### Encoding\n\nThere is a need to encode the non-numeric variables. Here they are: \n* *Gender*, \n* *Working Professional or Student*, \n* *Sleep Duration*, \n* *Dietary Habits*, \n* *Have you ever had suicidal thoughts ?*, \n* *Family History of Mental Illness*.","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import OrdinalEncoder\n\nencode_columns =      [\"Gender\", \n                       \"Sleep Duration\",\n                       \"Degree\",\n                       \"Dietary Habits\", \n                       \"Have you ever had suicidal thoughts ?\", \n                       \"Family History of Mental Illness\"]\n\n# Apply ordinal encoder \nordinal_encoder = OrdinalEncoder()\nX1_train[encode_columns] = ordinal_encoder.fit_transform(X1_train[encode_columns])\nX1_valid[encode_columns] = ordinal_encoder.transform(X1_valid[encode_columns])\n\nX2_train[encode_columns] = ordinal_encoder.fit_transform(X2_train[encode_columns])\nX2_valid[encode_columns] = ordinal_encoder.transform(X2_valid[encode_columns])\n\n\n# Apply for test data as well\nX1_test[encode_columns] = ordinal_encoder.transform(X1_test[encode_columns])\nX2_test[encode_columns] = ordinal_encoder.transform(X2_test[encode_columns])","metadata":{"execution":{"iopub.status.busy":"2024-11-20T10:07:51.631816Z","iopub.execute_input":"2024-11-20T10:07:51.632168Z","iopub.status.idle":"2024-11-20T10:07:51.990915Z","shell.execute_reply.started":"2024-11-20T10:07:51.632136Z","shell.execute_reply":"2024-11-20T10:07:51.989738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Tune the Model","metadata":{}},{"cell_type":"code","source":"# Define xgb to be your XGBClassifier.\nxgb = XGBClassifier(objective=\"binary:logistic\", random_state = 24)","metadata":{"execution":{"iopub.status.busy":"2024-11-20T10:07:51.992338Z","iopub.execute_input":"2024-11-20T10:07:51.992731Z","iopub.status.idle":"2024-11-20T10:07:51.998733Z","shell.execute_reply.started":"2024-11-20T10:07:51.992689Z","shell.execute_reply":"2024-11-20T10:07:51.997444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Define the parameters for hyperparameter tuning\n\nDefine the parameters for hyperparameter tuning\nTo identify suitable parameters for your xgboost model, first define the parameters for hy- perparameter tuning. Specifically, define a range of values for max_depth, min_child_weight, learning_rate, n_estimators, subsample, and colsample_bytree.\nConsider a more limited range for each parameter to allow for timely iteration and model training.","metadata":{}},{"cell_type":"code","source":"# Define parameters for tuning as `cv_params`.\ncv_prof_params = { \"max_depth\": [6],\n             \"min_child_weight\": [15],\n             \"learning_rate\": [0.15],\n             \"n_estimators\": [60],\n             \"subsample\": [0.5],\n             \"colsample_bytree\": [0.6]}\n\ncv_stud_params = { \"max_depth\": [4, 6, 8],\n             \"min_child_weight\": [25],\n             \"learning_rate\": [0.05, 0.15],\n             'n_estimators': [60, 100, 200],\n             'subsample': [0.6, 0.8],\n             'colsample_bytree': [0.4, 0.6]}\n\n# Construct the GridSearch.\n# Model for students\nxgb_cv_student = GridSearchCV(xgb, cv_stud_params, scoring = \"accuracy\", cv = 5, n_jobs = 5, refit = \"accuracy\")\n\n# Model for professionals\nxgb_cv_professional = GridSearchCV(xgb, cv_prof_params, scoring = \"accuracy\", cv = 5, n_jobs = 5, refit = \"accuracy\")","metadata":{"execution":{"iopub.status.busy":"2024-11-20T10:07:52.000369Z","iopub.execute_input":"2024-11-20T10:07:52.000823Z","iopub.status.idle":"2024-11-20T10:07:52.014410Z","shell.execute_reply.started":"2024-11-20T10:07:52.000781Z","shell.execute_reply":"2024-11-20T10:07:52.013041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# fit the GridSearch model to training data\nxgb_students = xgb_cv_student.fit(X1_train, y1_train)\nxgb_students","metadata":{"execution":{"iopub.status.busy":"2024-11-20T10:07:52.015778Z","iopub.execute_input":"2024-11-20T10:07:52.016152Z","iopub.status.idle":"2024-11-20T10:08:47.325610Z","shell.execute_reply.started":"2024-11-20T10:07:52.016115Z","shell.execute_reply":"2024-11-20T10:08:47.324325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# fit the GridSearch model to training data\nxgb_professionals = xgb_cv_professional.fit(X2_train, y2_train)\nxgb_professionals","metadata":{"execution":{"iopub.status.busy":"2024-11-20T10:08:47.327524Z","iopub.execute_input":"2024-11-20T10:08:47.327930Z","iopub.status.idle":"2024-11-20T10:08:50.073196Z","shell.execute_reply.started":"2024-11-20T10:08:47.327889Z","shell.execute_reply":"2024-11-20T10:08:50.072282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Results and evaluation","metadata":{}},{"cell_type":"code","source":"# Apply your model to predict on your test data. Call this output \"y_pred\".\ny1_pred = xgb_students.predict(X1_valid)","metadata":{"execution":{"iopub.status.busy":"2024-11-20T10:08:50.074416Z","iopub.execute_input":"2024-11-20T10:08:50.074880Z","iopub.status.idle":"2024-11-20T10:08:50.093527Z","shell.execute_reply.started":"2024-11-20T10:08:50.074840Z","shell.execute_reply":"2024-11-20T10:08:50.092540Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(xgb_students.best_params_)\nprint(xgb_students.best_score_)","metadata":{"execution":{"iopub.status.busy":"2024-11-20T10:08:50.094758Z","iopub.execute_input":"2024-11-20T10:08:50.095104Z","iopub.status.idle":"2024-11-20T10:08:50.111051Z","shell.execute_reply.started":"2024-11-20T10:08:50.095070Z","shell.execute_reply":"2024-11-20T10:08:50.109676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get predictions\naccuracy1 = accuracy_score(y1_valid, y1_pred)\n\nprint(accuracy1)","metadata":{"execution":{"iopub.status.busy":"2024-11-20T10:08:50.112476Z","iopub.execute_input":"2024-11-20T10:08:50.112888Z","iopub.status.idle":"2024-11-20T10:08:50.128608Z","shell.execute_reply.started":"2024-11-20T10:08:50.112848Z","shell.execute_reply":"2024-11-20T10:08:50.127517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\n\nsmote = SMOTE(random_state=42)\nX_smote, y_smote = smote.fit_resample(X1_train , y1_train)","metadata":{"execution":{"iopub.status.busy":"2024-11-20T10:08:50.130232Z","iopub.execute_input":"2024-11-20T10:08:50.130578Z","iopub.status.idle":"2024-11-20T10:08:50.816263Z","shell.execute_reply.started":"2024-11-20T10:08:50.130545Z","shell.execute_reply":"2024-11-20T10:08:50.815058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nrf_model = RandomForestClassifier(random_state=42)\nrf_model.fit(X_smote, y_smote)\nrf_score = rf_model.score(X1_valid , y1_valid)\nprint(f\"Random Forest Accuracy: {rf_score}\")","metadata":{"execution":{"iopub.status.busy":"2024-11-20T10:08:50.817602Z","iopub.execute_input":"2024-11-20T10:08:50.818117Z","iopub.status.idle":"2024-11-20T10:08:53.488538Z","shell.execute_reply.started":"2024-11-20T10:08:50.818082Z","shell.execute_reply":"2024-11-20T10:08:53.486985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Apply professionals model to predict on the test data.\ny2_pred = xgb_professionals.predict(X2_valid)\n\nprint(xgb_professionals.best_params_)\nprint(xgb_professionals.best_score_)","metadata":{"execution":{"iopub.status.busy":"2024-11-20T10:08:53.490282Z","iopub.execute_input":"2024-11-20T10:08:53.490816Z","iopub.status.idle":"2024-11-20T10:08:53.528383Z","shell.execute_reply.started":"2024-11-20T10:08:53.490761Z","shell.execute_reply":"2024-11-20T10:08:53.527461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Evaluate XGBoost model’s performance","metadata":{}},{"cell_type":"code","source":"# Get predictions\naccuracy2 = accuracy_score(y2_valid, y2_pred)\n\nprint(accuracy2)","metadata":{"execution":{"iopub.status.busy":"2024-11-20T10:08:53.529327Z","iopub.execute_input":"2024-11-20T10:08:53.529651Z","iopub.status.idle":"2024-11-20T10:08:53.546059Z","shell.execute_reply.started":"2024-11-20T10:08:53.529599Z","shell.execute_reply":"2024-11-20T10:08:53.544586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- The **XGBoost model** demonstrates strong performance with high accuracy, indicating that it makes accurate predictions.\n\nThis result suggests that XGBoost is a powerful model for predicting employee turnover.\n\n#### **Gain clarity with the confusion matrix**","metadata":{}},{"cell_type":"code","source":"# Construct and display the confusion matrix for students.\ncm = confusion_matrix(y1_valid, y1_pred, labels=xgb_students.classes_)\ndisp = ConfusionMatrixDisplay(confusion_matrix = cm,\n                             display_labels = xgb_students.classes_)\n# Plot the visual in-line.\ndisp.plot()","metadata":{"execution":{"iopub.status.busy":"2024-11-20T10:08:53.548133Z","iopub.execute_input":"2024-11-20T10:08:53.548476Z","iopub.status.idle":"2024-11-20T10:08:53.858763Z","shell.execute_reply.started":"2024-11-20T10:08:53.548444Z","shell.execute_reply":"2024-11-20T10:08:53.857546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Construct and display the confusion matrix for professionals.\ncm = confusion_matrix(y2_valid, y2_pred, labels=xgb_professionals.classes_)\ndisp = ConfusionMatrixDisplay(confusion_matrix = cm,\n                             display_labels = xgb_professionals.classes_)\n# Plot the visual in-line.\ndisp.plot()","metadata":{"execution":{"iopub.status.busy":"2024-11-20T10:08:53.860484Z","iopub.execute_input":"2024-11-20T10:08:53.860997Z","iopub.status.idle":"2024-11-20T10:08:54.151107Z","shell.execute_reply.started":"2024-11-20T10:08:53.860944Z","shell.execute_reply":"2024-11-20T10:08:54.149775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This indicates that the model is performing very well, with a low number of false predictions. Specifically, it has a very low **false positive** rate.\n\nThis indicates that the model is well-balanced between training and validation sets, and the false negatives and false positives indicate where the model might be improved.\n\n### Evaluate Feature Importance","metadata":{}},{"cell_type":"code","source":"import shap\n\nbest_model = xgb_students.best_estimator_\nexplainer = shap.Explainer(best_model, X1_valid)\nshap_values = explainer(X1_valid)\n\n# Visualize\nshap.summary_plot(shap_values, X1_valid)","metadata":{"execution":{"iopub.status.busy":"2024-11-20T10:08:54.152839Z","iopub.execute_input":"2024-11-20T10:08:54.153198Z","iopub.status.idle":"2024-11-20T10:09:48.327340Z","shell.execute_reply.started":"2024-11-20T10:08:54.153164Z","shell.execute_reply":"2024-11-20T10:09:48.325983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_model2 = xgb_professionals.best_estimator_\nexplainer2 = shap.Explainer(best_model2, X2_valid)\nshap_values2 = explainer(X2_valid)\n\n# Visualize\nshap.summary_plot(shap_values2, X2_valid)","metadata":{"execution":{"iopub.status.busy":"2024-11-20T10:09:48.329089Z","iopub.execute_input":"2024-11-20T10:09:48.330847Z","iopub.status.idle":"2024-11-20T10:13:14.226120Z","shell.execute_reply.started":"2024-11-20T10:09:48.330782Z","shell.execute_reply":"2024-11-20T10:13:14.224815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Visualize most important features","metadata":{}},{"cell_type":"code","source":"# Plot the relative feature importance of the predictor variables in the students model.\nplot_importance(xgb_students.best_estimator_)","metadata":{"execution":{"iopub.status.busy":"2024-11-20T10:13:14.227918Z","iopub.execute_input":"2024-11-20T10:13:14.228427Z","iopub.status.idle":"2024-11-20T10:13:14.549714Z","shell.execute_reply.started":"2024-11-20T10:13:14.228371Z","shell.execute_reply":"2024-11-20T10:13:14.548484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the relative feature importance of the predictor variables in the professionals model.\nplot_importance(xgb_professionals.best_estimator_)","metadata":{"execution":{"iopub.status.busy":"2024-11-20T10:13:14.551507Z","iopub.execute_input":"2024-11-20T10:13:14.552503Z","iopub.status.idle":"2024-11-20T10:13:15.098024Z","shell.execute_reply.started":"2024-11-20T10:13:14.552441Z","shell.execute_reply":"2024-11-20T10:13:15.096467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Adjust the Decision Threshold","metadata":{}},{"cell_type":"code","source":"# Predict probabilities\ny_valid_probs = xgb_students.predict_proba(X1_valid)[:, 1]\n\n# Adjust threshold\nthreshold = 0.45  # Lower threshold to reduce FNs\ny_valid_pred = (y_valid_probs >= threshold).astype(int)\n\n# Reevaluate\nprint(confusion_matrix(y1_valid, y_valid_pred))\nprint(classification_report(y1_valid, y_valid_pred))","metadata":{"execution":{"iopub.status.busy":"2024-11-20T10:13:15.099822Z","iopub.execute_input":"2024-11-20T10:13:15.100422Z","iopub.status.idle":"2024-11-20T10:13:15.147327Z","shell.execute_reply.started":"2024-11-20T10:13:15.100356Z","shell.execute_reply":"2024-11-20T10:13:15.145560Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Combine Predictions\nCombine the predictions for students and professionals back into a single array.","metadata":{}},{"cell_type":"code","source":"# Initialize an empty predictions DataFrame with the same indices as X_test\ntest_preds = pd.Series(0, index=df_test.index)\n\n# Predict for students if there are any\nif not X1_test.empty:\n    student_test_probs  = xgb_students.predict_proba(X1_test)[:, 1]\n    # Adjust threshold\n    threshold = 0.45  # Lower threshold to reduce FNs\n    student_test_predictions = (student_test_probs >= threshold).astype(int)\n    # Assign predictions for students\n    test_preds.loc[X1_test.index] = student_test_predictions\n\n# Predict for professionals if there are any\nif not X2_test.empty:\n    professional_test_predictions = xgb_professionals.predict(X2_test)\n    # Assign predictions for professionals\n    test_preds.loc[X2_test.index] = professional_test_predictions\n\n# Convert predictions to integers\ntest_preds = test_preds.astype(int)","metadata":{"execution":{"iopub.status.busy":"2024-11-20T10:13:15.149085Z","iopub.execute_input":"2024-11-20T10:13:15.149447Z","iopub.status.idle":"2024-11-20T10:13:15.256400Z","shell.execute_reply.started":"2024-11-20T10:13:15.149409Z","shell.execute_reply":"2024-11-20T10:13:15.255531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Evaluate Combined Predictions\nFinally, evaluate the combined predictions against the actual Depression labels.","metadata":{}},{"cell_type":"code","source":"print(xgb_students.best_score_)\nprint(xgb_professionals.best_score_)","metadata":{"execution":{"iopub.status.busy":"2024-11-20T10:13:15.257378Z","iopub.execute_input":"2024-11-20T10:13:15.257718Z","iopub.status.idle":"2024-11-20T10:13:15.267528Z","shell.execute_reply.started":"2024-11-20T10:13:15.257684Z","shell.execute_reply":"2024-11-20T10:13:15.266359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Prepare the test data and make the submitable predictions","metadata":{}},{"cell_type":"code","source":"# Save test predictions to file\noutput = pd.DataFrame({\"id\": df_test.index,\n                       \"Depression\": test_preds})\noutput.to_csv(\"submission.csv\", index = False)","metadata":{"execution":{"iopub.status.busy":"2024-11-20T10:13:15.268850Z","iopub.execute_input":"2024-11-20T10:13:15.269306Z","iopub.status.idle":"2024-11-20T10:13:15.352521Z","shell.execute_reply.started":"2024-11-20T10:13:15.269248Z","shell.execute_reply":"2024-11-20T10:13:15.351351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output.head()","metadata":{"execution":{"iopub.status.busy":"2024-11-20T10:13:15.354198Z","iopub.execute_input":"2024-11-20T10:13:15.354580Z","iopub.status.idle":"2024-11-20T10:13:15.366795Z","shell.execute_reply.started":"2024-11-20T10:13:15.354544Z","shell.execute_reply":"2024-11-20T10:13:15.365346Z"},"trusted":true},"execution_count":null,"outputs":[]}]}